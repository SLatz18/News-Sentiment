import requests
from textblob import TextBlob
import pandas as pd

# API Key for NewsAPI (replace with your own API key)
NEWS_API_KEY = "yourcodehere"
NYT_API_KEY = 'yourcodehere'

# Step 1: Fetch News Articles from NewsAPI
def fetch_news_api():
    """
    Fetch top news articles from NewsAPI.
    Returns a DataFrame with article titles and URLs.
    """
    url = f"https://newsapi.org/v2/top-headlines?country=us&apiKey={NEWS_API_KEY}"
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise HTTPError for bad responses (4xx, 5xx)
        articles = response.json().get("articles", [])
        return pd.DataFrame(articles)
    except requests.exceptions.RequestException as e:
        print(f"Error fetching news: {e}")
        return pd.DataFrame()

# Step 2: Fetch News Articles from New York Times API
def fetch_nyt_api():
    """
    Fetch top news articles from New York Times API.
    Returns a DataFrame with article titles and URLs.
    """
    url = f'https://api.nytimes.com/svc/topstories/v2/home.json?api-key={NYT_API_KEY}'
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise HTTPError for bad responses (4xx, 5xx)
        articles = response.json().get("results", [])
        return pd.DataFrame(articles)
    except requests.exceptions.RequestException as e:
        print(f"Error fetching news: {e}")
        return pd.DataFrame()

# Step 3: Merge News Data from Multiple Sources
def merge_news_data(news_api_data, nyt_api_data):
    """
    Merge news data from NewsAPI and New York Times API.
    Returns a DataFrame with merged news articles.
    """
    news_api_data = news_api_data[['source', 'title', 'description', 'url']]
    nyt_api_data = nyt_api_data[['title', 'abstract', 'url']]
    nyt_api_data.rename(columns={'abstract': 'description'}, inplace=True)
    nyt_api_data['source'] = 'New York Times'
    
    merged_data = pd.concat([news_api_data, nyt_api_data], ignore_index=True)
    return merged_data

# Step 2: Analyze Sentiment with Keyword Filtering
def analyze_sentiment(df):
    """
    Perform sentiment analysis on news article titles with keyword filtering.
    Filters out negative stories before applying sentiment analysis.
    """
    if df.empty:
        print("No articles fetched. Exiting sentiment analysis.")
        return df

    # Define negative keywords to exclude
    negative_keywords = ["injure", "kill", "crash", "violence", "death", "attack", "hurt", "disaster"]

    def contains_negative_keywords(text):
        return any(keyword in text.lower() for keyword in negative_keywords)

    def get_sentiment(text):
        blob = TextBlob(text)
        return blob.sentiment.polarity  # Sentiment score (-1 to 1)

    # Filter out articles with negative keywords
    df = df[~df['title'].apply(contains_negative_keywords)]

    # Add sentiment scores
    df['sentiment'] = df['title'].apply(get_sentiment)

    # Filter for positive articles (adjust threshold as needed)
    positive_df = df[df['sentiment'] > 0.3]
    return positive_df

# Step 3: Display Positive News
def display_positive_news(df):
    """
    Print the positive news articles with sentiment scores.
    """
    if df.empty:
        print("No positive news stories found.")
    else:
        print("Positive News Stories:")
        for _, row in df.iterrows():
            print(f"Title: {row['title']}")
            print(f"Sentiment Score: {row['sentiment']:.2f}")
            print(f"URL: {row['url']}")
            print("-" * 50)

# Main Program
if __name__ == "__main__":
    # Fetch News
    news_api_data = fetch_news_api()
    nyt_api_data = fetch_nyt_api()
    merged_data = merge_news_data(news_api_data, nyt_api_data)
    articles = pd.DataFrame(merged_data)

    # Analyze Sentiment
    positive_news = analyze_sentiment(articles)

    # Display Positive News
    display_positive_news(positive_news)
